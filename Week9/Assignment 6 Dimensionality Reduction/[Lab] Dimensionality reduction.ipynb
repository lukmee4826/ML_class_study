{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b9a3486",
   "metadata": {},
   "source": [
    "# LAB: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00527822",
   "metadata": {},
   "source": [
    "**Load necessary packages and apply custom configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce58d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.8.8\n",
      "Numpy version 1.20.1\n",
      "Scipy version 1.6.2\n",
      "Pandas version 1.2.4\n",
      "Matplotlib version 3.3.4\n",
      "Seaborn version 0.11.1\n"
     ]
    }
   ],
   "source": [
    "import warnings; \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\",category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\",category=FutureWarning)\n",
    "\n",
    "# Suppress valuewarning when fitting ARIMA model.\n",
    "from statsmodels.tools.sm_exceptions import ValueWarning\n",
    "warnings.simplefilter('ignore', ValueWarning)\n",
    "\n",
    "\n",
    "# Interactive plots embedded within the notebook\n",
    "#%matplotlib notebook \n",
    "# Static images of plots embedded within the notebook\n",
    "# %matplotlib inline   \n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "from platform import python_version\n",
    "\n",
    "#pd.options.plotting.backend = \"plotly\" \n",
    "# Conflict with options in original matplotlib.\n",
    "\n",
    "print('Python version', python_version())\n",
    "print('Numpy version', np.__version__)\n",
    "print('Scipy version', sp.__version__)\n",
    "print('Pandas version', pd.__version__)\n",
    "print('Matplotlib version', mpl.__version__)\n",
    "print('Seaborn version', sns.__version__)\n",
    "###############################################\n",
    "\n",
    "#plt.style.use('ggplot')\n",
    "#plt.style.use('seaborn-v0_8-muted')\n",
    "plt.rcParams['figure.figsize'] = (6, 6)\n",
    "plt.rcParams['grid.linestyle'] = ':'   \n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "#sns.color_palette(\"RdBu\", n_colors=10)\n",
    "#sns.color_palette(\"RdBu_r') # Good for heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c3029",
   "metadata": {},
   "source": [
    "# Part I: Linear PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0845e",
   "metadata": {},
   "source": [
    "**Create a dataset**   \n",
    "rows = instances, columns = features/variables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fa47fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9 39]\n",
      " [15 56]\n",
      " [25 93]\n",
      " [14 61]\n",
      " [10 50]\n",
      " [18 75]\n",
      " [ 0 32]\n",
      " [16 85]\n",
      " [ 5 42]\n",
      " [19 70]\n",
      " [16 66]\n",
      " [20 80]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([9,15,25,14,10,18,0,16,5,19,16,20])\n",
    "x2 = np.array([39,56,93,61,50,75,32,85,42,70,66,80])\n",
    "\n",
    "D = np.vstack((x1,x2)).T \n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d094a1",
   "metadata": {},
   "source": [
    "Make the dataset zero-mean by subtracting each column by its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d1f871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.91666667 -23.41666667]\n",
      " [  1.08333333  -6.41666667]\n",
      " [ 11.08333333  30.58333333]\n",
      " [  0.08333333  -1.41666667]\n",
      " [ -3.91666667 -12.41666667]\n",
      " [  4.08333333  12.58333333]\n",
      " [-13.91666667 -30.41666667]\n",
      " [  2.08333333  22.58333333]\n",
      " [ -8.91666667 -20.41666667]\n",
      " [  5.08333333   7.58333333]\n",
      " [  2.08333333   3.58333333]\n",
      " [  6.08333333  17.58333333]]\n"
     ]
    }
   ],
   "source": [
    "D = np.vstack((x1, x2)).T   #matrix(12,2)\n",
    "mean_D = np.mean(D, axis=0) \n",
    "D_zero_mean = D - mean_D\n",
    "\n",
    "print(D_zero_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d92ae",
   "metadata": {},
   "source": [
    "Compute the sample covariance matrix $S$ from the zero-mean data using `np.cov`.  \n",
    "    \n",
    "   \n",
    "Use the option `rowvar=False` to treat the variables column-wise.  \n",
    "The sum is divided by  $N-1$ by default (option `bias=False` or `ddof=1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef24ca53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 47.71969697 122.9469697 ]\n",
      " [122.9469697  370.08333333]]\n"
     ]
    }
   ],
   "source": [
    "Sample_covar_matrix = np.cov(D_zero_mean, rowvar=False)\n",
    "print(Sample_covar_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b713fa72",
   "metadata": {},
   "source": [
    "Compute the eigenpairs of the covariance matrix $S$ to get the principal components.  \n",
    "Show the eigenvectors sorted by the largest eigenvalues first, and the corresponding eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5288d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "egval,egvec = np.linalg.eig(Sample_covar_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "243d2169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.18117609 411.62185422]\n",
      "[[-0.94738969 -0.32008244]\n",
      " [ 0.32008244 -0.94738969]]\n"
     ]
    }
   ],
   "source": [
    "print(egval)\n",
    "print(egvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee03accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[411.62185422   6.18117609]\n",
      "[[-0.32008244 -0.94738969]\n",
      " [-0.94738969  0.32008244]]\n"
     ]
    }
   ],
   "source": [
    "sorted_indices = np.argsort(egval)[::-1]\n",
    "egval = egval[sorted_indices]\n",
    "egvec = egvec[:, sorted_indices]\n",
    "print(egval)\n",
    "print(egvec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a540a",
   "metadata": {},
   "source": [
    "Result: Eigenvalues = 441.6218 , 6.1811"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e39af",
   "metadata": {},
   "source": [
    "Take $r=2$ principal components as the matrix `Pr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61010d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components Matrix (Pr):\n",
      "[[-0.32008244 -0.94738969]\n",
      " [-0.94738969  0.32008244]]\n"
     ]
    }
   ],
   "source": [
    "# เลือก 2 principal components\n",
    "r = 2\n",
    "Pr = egvec[:, :r]  # เลือก 2 คอลัมน์แรกของ eigenvectors ที่เรียงลำดับแล้ว\n",
    "\n",
    "# แสดงผล\n",
    "print(\"Principal Components Matrix (Pr):\")\n",
    "print(Pr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826d140",
   "metadata": {},
   "source": [
    "Transform the data to obtain the reduced-dimension data $Z$ by multiplying  \n",
    "    the zero-mean data $X$ to the matrix of principal components $Pr$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4ea4a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced-Dimension Data (Z):\n",
      "[[ 23.75844731  -2.83726457]\n",
      " [  5.73232788  -3.08020118]\n",
      " [-32.52191518  -0.71104768]\n",
      " [  1.31546186  -0.53239927]\n",
      " [ 13.01707825  -0.26374738]\n",
      " [-13.22832361   0.15919617]\n",
      " [ 33.27091715   3.44866555]\n",
      " [-22.06205564   5.2548    ]\n",
      " [ 22.19660801   1.91254153]\n",
      " [ -8.81145759  -2.38860574]\n",
      " [ -4.06165149  -0.82676644]\n",
      " [-18.60543696  -0.13517099]]\n"
     ]
    }
   ],
   "source": [
    "# Transform ข้อมูลไปยัง reduced-dimension space\n",
    "Z = D_zero_mean @ Pr\n",
    "\n",
    "# แสดงผล\n",
    "print(\"Reduced-Dimension Data (Z):\")\n",
    "print(Z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6305c200",
   "metadata": {},
   "source": [
    "Inverse-transform the data by multiplying the transformed data and the matrix of principal components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a9fcf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.32008244 -0.94738969]\n",
      " [-0.94738969  0.32008244]]\n"
     ]
    }
   ],
   "source": [
    "Pr_T = Pr.T  # Transpose ของ Pr\n",
    "print(Pr_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae1637",
   "metadata": {},
   "source": [
    "<font color='blue'>Determine the variance explained by each principal component from the eigenvalues, \n",
    "the PVEs and the cumulative PVEs from the eigenvalues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30995607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [411.62185422   6.18117609]\n",
      "Proportion of Variance Explained (PVE): [0.98520553 0.01479447]\n",
      "Cumulative PVE: [0.98520553 1.        ]\n"
     ]
    }
   ],
   "source": [
    "total_variance = np.sum(egval)\n",
    "pve = egval / total_variance\n",
    "\n",
    "# คำนวณ Cumulative PVE\n",
    "cumulative_pve = np.cumsum(pve)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"Eigenvalues:\", egval)\n",
    "print(\"Proportion of Variance Explained (PVE):\", pve)\n",
    "print(\"Cumulative PVE:\", cumulative_pve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f96d86",
   "metadata": {},
   "source": [
    "# Part II: Dimensionaltiy reduction with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1655d",
   "metadata": {},
   "source": [
    "The dataset from sheet `MTCARS` in file `dimensionality-reduction.xlsx`. The dataset contains 11 columns:\n",
    "- `mpg`: Miles per gallon (Fuel efficience)\n",
    "- `cyl`: Number of cyclinders  \n",
    "- `disp`: Displacement (Proxy to power generated by engine)  \n",
    "- `hp`: Gross horse power  (Engine power output)\n",
    "- `drat`: Rear axle ratio (# turns of the drive shaft for every one rotation of the wheel axle). \n",
    "          High ratio = More torque\n",
    "- `wt`: Weight in 1000lbs\n",
    "- `qsec`: 1/4 mile time (Fastest time to travel 1/4 mile in seconds)\n",
    "- `vs`: Engine cylinder configuration (V-shape or Straight line)\n",
    "- `am`: Transmission Type (Automatic or Manual)\n",
    "- `gear`: Number of forward gears\n",
    "- `carb`: Number of carburetors. Engines with higher displacement typically have higher barrel configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c23dc",
   "metadata": {},
   "source": [
    "Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec554f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "836a546f",
   "metadata": {},
   "source": [
    "Compute the covariance matrix of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51b3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "341579ab",
   "metadata": {},
   "source": [
    "Compute the eigenvectors and the eigenvalues of the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dffc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c59cbbc",
   "metadata": {},
   "source": [
    "Computer the PVE of principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36b417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adfe3037",
   "metadata": {},
   "source": [
    "**<font color='darkorange'>Question 2.1</font>**\n",
    "- (a) How many PCs are sufficient to explain at least approximately 90% of the total variation in the data ?\n",
    "- (b) Which of the original features get large weights (loadings) in PC1 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66f4c79",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb13562d",
   "metadata": {},
   "source": [
    "Standardize the data with `StandardScaler()` in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4b6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0df3979",
   "metadata": {},
   "source": [
    "Compute the covariance matrix of the standardized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070a118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee420b44",
   "metadata": {},
   "source": [
    "Compute the eigenvectors and the eigenvalues of the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9c865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55d620fb",
   "metadata": {},
   "source": [
    "Computer the PVE of principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7952f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8923fc1",
   "metadata": {},
   "source": [
    "**<font color='darkorange'>Question 2.2</font>**\n",
    "- (a) How many PCs are sufficient to explain at least approximately 90% of the total variation in the data ?\n",
    "- (b) Which of the original features get large weights (loadings) in PC1 ?\n",
    "- (c) Do the PCA outputs differ significantly between standardizing and not standardizing the dataset before applying PCA? Explain the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76240ba0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
