{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7d9386",
   "metadata": {},
   "source": [
    "Install keras and scikit-learn Keras with     \n",
    "```!conda install keras ```  \n",
    "```!pip install tensorflow==2.17.0```  \n",
    "```!pip install scikeras```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5dc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\",category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\",category=FutureWarning)\n",
    "\n",
    "# Suppress valuewarning when fitting ARIMA model.\n",
    "from statsmodels.tools.sm_exceptions import ValueWarning\n",
    "warnings.simplefilter('ignore', ValueWarning)\n",
    "\n",
    "\n",
    "# Interactive plots embedded within the notebook\n",
    "#%matplotlib notebook \n",
    "# Static images of plots embedded within the notebook\n",
    "# %matplotlib inline   \n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from platform import python_version\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels as stm\n",
    "import sklearn \n",
    "import keras \n",
    "import scikeras\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Python version', python_version())\n",
    "print('Numpy version', np.__version__)\n",
    "print('Scipy version', sp.__version__)\n",
    "print('Pandas version', pd.__version__)\n",
    "print('Matplotlib version', mpl.__version__)\n",
    "print('Seaborn version', sns.__version__)\n",
    "print('Statsmodels version', stm.__version__)\n",
    "print('Tensor flow version ', tf.__version__)\n",
    "print('Scikit-learn version', sklearn.__version__)\n",
    "print('Kera version', keras.__version__)\n",
    "print('Scikeras learn version ', scikeras.__version__)\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Helvetica']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6875090b",
   "metadata": {},
   "source": [
    "## <font color='orange'>Your Turn: House Price Prediction</font>\n",
    "\n",
    "In this activity, we will use feed-forward MLP/NN for regression on the California\n",
    "housing dataset ```\\data\\california-housing.csv```. <br> \n",
    "Each column has the following meaning:\n",
    "1. `longitude`: A measure of how far west a house is; a higher value is farther west\n",
    "2. `latitude`: A measure of how far north a house is; a higher value is farther north\n",
    "3. `housingMedianAge`: Median age of a house within a block; a lower number is a newer building\n",
    "4. `totalRooms`: Total number of rooms within a block\n",
    "5. `totalBedrooms`: Total number of bedrooms within a block\n",
    "6. `population`: Total number of people residing within a block\n",
    "7. `households`: Total number of households, a group of people residing within a home unit, for a block\n",
    "8. `medianIncome`: Median income for households within a block of houses (measured in tens of thousands of US Dollars)\n",
    "9. `medianHouseValue` (**Prediction Target**): Median house value for households within a block (measured in US Dollars)\n",
    "10. `oceanProximity`: Location of the house w.r.t ocean/sea\n",
    "\n",
    "Your task is to explore the data, create the feed-forward NN with only numeric columns, fit and diagnose the learning curve.  \n",
    "You could play with the model configuration to improve the prediction results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b95e3a",
   "metadata": {},
   "source": [
    "### Load, explore, and preprocess the data \n",
    "- Check basic information of dataset\n",
    "- For ease of implementation, we will use only numeric features to build the model.\n",
    "- Split the data into 80% train set and 20% test set. \n",
    "- Apply `StandardScaler` to the numeric features and target. Pipeline may not be necessary as we only have one transformation step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defb67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba31015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f877d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b9bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9fa8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02107be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "915e40a3",
   "metadata": {},
   "source": [
    "Preprocess the model inputs with standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e92d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ceb2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de3b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e8c2034",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb8f41",
   "metadata": {},
   "source": [
    "#### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0af71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad2496f5",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a314a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e29f9947",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb5098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c1917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105ea78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ce822db",
   "metadata": {},
   "source": [
    "### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868b094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9081aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65437b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8944f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
