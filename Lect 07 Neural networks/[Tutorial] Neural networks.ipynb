{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7d9386",
   "metadata": {},
   "source": [
    "Install keras and scikit-learn Keras with     \n",
    "```!conda install keras ```  \n",
    "```!pip install tensorflow==2.17.0```  \n",
    "```!pip install scikeras```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5dc501",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikeras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscikeras\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython version\u001b[39m\u001b[38;5;124m'\u001b[39m, python_version())\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikeras'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\",category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\",category=FutureWarning)\n",
    "\n",
    "# Suppress valuewarning when fitting ARIMA model.\n",
    "from statsmodels.tools.sm_exceptions import ValueWarning\n",
    "warnings.simplefilter('ignore', ValueWarning)\n",
    "\n",
    "\n",
    "# Interactive plots embedded within the notebook\n",
    "#%matplotlib notebook \n",
    "# Static images of plots embedded within the notebook\n",
    "# %matplotlib inline   \n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from platform import python_version\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels as stm\n",
    "import sklearn \n",
    "import keras \n",
    "import scikeras\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Python version', python_version())\n",
    "print('Numpy version', np.__version__)\n",
    "print('Scipy version', sp.__version__)\n",
    "print('Pandas version', pd.__version__)\n",
    "print('Matplotlib version', mpl.__version__)\n",
    "print('Seaborn version', sns.__version__)\n",
    "print('Statsmodels version', stm.__version__)\n",
    "print('Tensor flow version ', tf.__version__)\n",
    "print('Scikit-learn version', sklearn.__version__)\n",
    "print('Kera version', keras.__version__)\n",
    "print('Scikeras learn version ', scikeras.__version__)\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Helvetica']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c069ed",
   "metadata": {},
   "source": [
    "## Neural Network Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ec43a",
   "metadata": {},
   "source": [
    "###  Explore the house sale dataset and prepare the input\n",
    "\n",
    "We will use a house price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20644194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "house_df = pd.read_csv('data/house_sales.csv', sep='\\t')\n",
    "house_df.head()\n",
    "house_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e37f4",
   "metadata": {},
   "source": [
    "Select columns to be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c109d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = [\"SqFtTotLiving\", \"SqFtLot\", \"Bathrooms\", \"Bedrooms\", \n",
    "               \"BldgGrade\", \"NbrLivingUnits\",\"SqFtFinBasement\"]\n",
    "cat_columns = ['PropertyType', 'NewConstruction']\n",
    "target_column = ['AdjSalePrice']\n",
    "house_df = house_df[num_columns + cat_columns + target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fb6c2",
   "metadata": {},
   "source": [
    "Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef17021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "house_train, house_test = train_test_split(house_df, test_size=0.25, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e4aca4",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We need to scale the input as GD is highly sensitive to scaling difference.  \n",
    "The output scaling should be performed if the range of y is more than hundreds or thousands as    \n",
    "a large magnitude will affect the convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771b0c6",
   "metadata": {},
   "source": [
    "### Transformation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead3d2b",
   "metadata": {},
   "source": [
    "Define the components in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f778c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Can add more steps to the pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_columns),\n",
    "    (\"cat\", OneHotEncoder(drop='first', handle_unknown='ignore', \n",
    "                          dtype=int, sparse_output=False), cat_columns)], remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3a122",
   "metadata": {},
   "source": [
    "Apply the pipeline to transform the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc8db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = full_pipeline.fit_transform(house_train)\n",
    "X_train = pd.DataFrame(X_transformed, columns=full_pipeline.get_feature_names_out())\n",
    "y_train = np.log(house_train[target_column]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cbd38b",
   "metadata": {},
   "source": [
    "Look at shape and dimension of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae7603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Train set Feature shape: {X_train.shape}, Dim: {X_train.ndim}') \n",
    "print(f'Train set Target shape: {y_train.shape}, Dim: {y_train.ndim}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c7c33c",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9292c026",
   "metadata": {},
   "source": [
    "### Create a feed-forward neural network \n",
    "\n",
    "Network with one input layer, two hidden layers and one output layer <br>\n",
    "https://keras.io/layers/core/\n",
    "\n",
    "- The hidden layers respectively have 16 and 4 nodes, all with tanh activation. \n",
    "  We will call it **tanh(16,4)** hidden layer configuration.\n",
    "- The output layer has 1 node with ReLU activation.   \n",
    "\n",
    "The warnings will be resolved by updating tf1.14 to 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c36a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "network = Sequential([      \n",
    "    Dense(16, activation='tanh', input_shape=X_train.shape[1:]),\n",
    "    Dense(4, activation='tanh'),\n",
    "    Dense(1, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f03bd6",
   "metadata": {},
   "source": [
    "<font color='blue'>**Configure the model for training and check its configuration**</font>\n",
    "- Optimization algorithm\n",
    "- Loss function to optimize\n",
    "- Metric to visualize the training performance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919804a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3afa968c",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd5bdd3",
   "metadata": {},
   "source": [
    "Fit the model and let it validate the test data in each training epoch. <br>\n",
    "`history` returned by fit() is a dictionary containing metrics being monitored during training and validation. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23949ca",
   "metadata": {},
   "source": [
    "<font color='blue'>Train the model using `.fit()`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587b917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b7eada2",
   "metadata": {},
   "source": [
    "### Save pipeline and trained model for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf3f84",
   "metadata": {},
   "source": [
    "We can use `pickle` package to save the transformation pipeline and the fitted model, which can later be retrieved.  \n",
    "The model weights can also be saved to and loaded from file by using `save_weights('file.h5')`   and `load_weights('file.h5')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91295fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(full_pipeline, open(\"house_pipeline.pickle\", \"wb\"))\n",
    "pickle.dump(network, open(\"house_nn_model.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819fc6f",
   "metadata": {},
   "source": [
    "### Evaluate the train loss and train metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79983827",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_metric = network.evaluate(X_train, y_train)\n",
    "print(f'Train Loss: {train_loss}\\nTrain Metric: {train_metric}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f53295",
   "metadata": {},
   "source": [
    "## Learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbbe1e0",
   "metadata": {},
   "source": [
    "Let's take the metrics recorded in history for the training data and validation data. <br>\n",
    "In the case of neural networks, the loss is usually negative log-likelihood and residual sum of squares <br>\n",
    "for classification and regression respectively.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1c6e6",
   "metadata": {},
   "source": [
    "Plot the training and validation losses over epoches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[['loss','val_loss']].plot(style=['bs:','ro-'], \n",
    "                                     ms=3, lw=1.5, alpha=0.5, figsize=(6, 4));\n",
    "plt.grid(True);\n",
    "plt.gca().set_ylim(0, 1) \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb27f2",
   "metadata": {},
   "source": [
    "## Performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a416f",
   "metadata": {},
   "source": [
    "### Trained performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "y_pred = network.predict(X_train)\n",
    "\n",
    "print(f'MSE on train data: {MSE(y_train,y_pred):2f}')\n",
    "print(f'MAPE on train data: {MAPE(y_train,y_pred):.3f}%\\n')\n",
    "print(f'MSE on train data (unscaled): {MSE(np.exp(y_train),np.exp(y_pred)):2f}')\n",
    "print(f'MAPE on train data (unscaled): {MAPE(np.exp(y_train),np.exp(y_pred)):.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fadb69",
   "metadata": {},
   "source": [
    "### Test performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee558b",
   "metadata": {},
   "source": [
    "Load the saved transformation pipeline and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "loaded_pipeline = pickle.load(open(\"house_pipeline.pickle\", \"rb\"))\n",
    "loaded_model = pickle.load(open(\"house_nn_model.pickle\", \"rb\"))\n",
    "\n",
    "X_test_transformed = loaded_pipeline.transform(house_test)\n",
    "y_test = np.log(house_test[target_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a8cf5",
   "metadata": {},
   "source": [
    "Apply the model to test data and determine the test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb4831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "y_test_pred = loaded_model.predict(X_test_transformed)\n",
    "print(f'MSE on test data: {MSE(y_test, y_test_pred):2f}')\n",
    "print(f'MAPE on test data: {MAPE(y_test, y_test_pred):.3f}%\\n')\n",
    "\n",
    "print(f'MSE on train data (unscaled): {MSE(np.exp(y_test),np.exp(y_test_pred)):2f}')\n",
    "print(f'MAPE on train data (unscaled): {MAPE(np.exp(y_test),np.exp(y_test_pred)):.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a7f2d",
   "metadata": {},
   "source": [
    "## Weight Regularization and Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c921f",
   "metadata": {},
   "source": [
    "Dropout layer prevents neurons to update their weights with some probability in each training step.  \n",
    "Weight regularization forces redundant weights to zero by including weights in the loss function.\n",
    "\n",
    "Example: Consider a network with two hidden layers. To add dropout to each hidden layer, \n",
    "```\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "reg_network = Sequential([\n",
    "    Dense(16, activation='tanh', input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l2(0.02)),\n",
    "    Dropout(rate=0.2),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dropout(rate=0.2),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "reg_network.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[wape])\n",
    "reg_network.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e99aaa8",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12a09e",
   "metadata": {},
   "source": [
    "### Define the hyperparameter range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508436aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDENLAYER1 = [8, 12]\n",
    "HIDDENLAYER2 = [4, 8]\n",
    "LEARN_RATE = [1e-2, 1e-3, 1e-4]\n",
    "DROPOUT_RATE = [0.2, 0.3, 0.4]\n",
    "BATCH_SIZE = [8, 16, 32]\n",
    "EPOCHS = [100, 200]\n",
    "\n",
    "\n",
    "grid_params = dict(\n",
    "    hiddenLayerOne=HIDDENLAYER1,\n",
    "    hiddenLayerTwo=HIDDENLAYER2,\n",
    "    dropout=DROPOUT_RATE,\n",
    "    learnRate=LEARN_RATE,\n",
    "    optimizer__batch_size=BATCH_SIZE,\n",
    "    optimizer__epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b22dd6",
   "metadata": {},
   "source": [
    "### Define the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# define baseline model\n",
    "# Other parameters such as the activation function and loss function can also be tuned.\n",
    "def baseline_model(inShape, hiddenLayerOne, hiddenLayerTwo, learnRate, dropout):\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential([\n",
    "        Dense(hiddenLayerOne, activation='tanh', input_shape=inShape),\n",
    "        Dropout(rate=dropout),\n",
    "        Dense(hiddenLayerTwo, activation='tanh'),\n",
    "        Dropout(rate=dropout),\n",
    "        Dense(1, activation='relu')\n",
    "    ])\n",
    "    \n",
    "    # compile model \n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learnRate), loss='mse')\n",
    "    model.summary()\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ce68e",
   "metadata": {},
   "source": [
    "### Perform Randomized Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056409d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "# wrap our model into a scikit-learn compatible classifier\n",
    "base_estimator = KerasRegressor(build_fn=baseline_model, verbose = 1, inShape=X_train.shape[1:],\n",
    "                                hiddenLayerOne=4, hiddenLayerTwo=4, learnRate = 0.1, dropout=0.2)\n",
    "\n",
    "print(\"Performing random search...\")\n",
    "searcher = RandomizedSearchCV(estimator=base_estimator, cv=3,\n",
    "                              param_distributions=grid_params, \n",
    "                              scoring='neg_mean_absolute_percentage_error')\n",
    "searchResults = searcher.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9f152f",
   "metadata": {},
   "source": [
    "### Evaluate the tuned model on the trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26eeabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize grid search information\n",
    "bestScore = searchResults.best_score_\n",
    "bestParams = searchResults.best_params_\n",
    "print(f'Best MAPE is {-bestScore:.2f}% using \\n{bestParams}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b5b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "tuned_model = searchResults.best_estimator_\n",
    "y_pred = tuned_model.predict(X_train)\n",
    "\n",
    "print(f'MSE on train data: {MSE(y_train,y_pred):2f}')\n",
    "print(f'MAPE on train data: {MAPE(y_train,y_pred):.3f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
